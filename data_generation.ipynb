{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8ec6de",
   "metadata": {},
   "source": [
    "Teste LGANM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2742ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ETH\\Thesis\\Code\\sempler-master\\.venv\\Lib\\site-packages\\sempler\\__init__.py:10: UserWarning: cannot import name 'NULL' from 'rpy2.rinterface_lib.sexp' (c:\\ETH\\Thesis\\Code\\sempler-master\\.venv\\Lib\\site-packages\\rpy2\\rinterface_lib\\sexp.py). Did not load sempler.semi module and sempler.DRFNet class - optional dependencies are missing. See https://github.com/juangamella/sempler#installation for more details. All other functionality is available.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sempler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Connectivity matrix\n",
    "W = np.array([[0, 0, 0, 0.1, 0],\n",
    "              [0, 0, 2.1, 0, 0],\n",
    "              [0, 0, 0, 3.2, 0],\n",
    "              [0, 0, 0, 0, 5.0],\n",
    "              [0, 0, 0, 0, 0]])\n",
    "\n",
    "# All together\n",
    "lganm = sempler.LGANM(W, (0, 1), (0, 1))\n",
    "\n",
    "# Sampling from the observational setting\n",
    "samples = lganm.sample(100)\n",
    "\n",
    "# Sampling under a shift intervention on variable 1 with standard gaussian noise\n",
    "samples = lganm.sample(100, shift_interventions={1: (0, 1)})\n",
    "\n",
    "# Sampling the observational environment in the \"population setting\"\n",
    "distribution = lganm.sample(population=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9e91488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n",
      "[ 0.07063424  0.82076854  1.85522887  6.43567917 32.58087994]\n",
      "covariance:\n",
      "[[1.37192846e-01 0.00000000e+00 0.00000000e+00 1.37192846e-02\n",
      "  6.85964232e-02]\n",
      " [0.00000000e+00 2.28100741e-01 4.79011557e-01 1.53283698e+00\n",
      "  7.66418491e+00]\n",
      " [0.00000000e+00 4.79011557e-01 1.92827632e+00 6.17048422e+00\n",
      "  3.08524211e+01]\n",
      " [1.37192846e-02 1.53283698e+00 6.17048422e+00 2.00654081e+01\n",
      "  1.00327040e+02]\n",
      " [6.85964232e-02 7.66418491e+00 3.08524211e+01 1.00327040e+02\n",
      "  5.01839834e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb9700",
   "metadata": {},
   "source": [
    "Teste ANM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1ae525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sempler\n",
    "import sempler.noise as noise\n",
    "import numpy as np\n",
    "\n",
    "# Connectivity matrix\n",
    "A = np.array([[0, 0, 0, 1, 0],\n",
    "              [0, 0, 1, 0, 0],\n",
    "              [0, 0, 0, 1, 0],\n",
    "              [0, 0, 0, 0, 1],\n",
    "              [0, 0, 0, 0, 0]])\n",
    "\n",
    "# Noise distributions (see sempler.noise)\n",
    "noise_distributions = [noise.normal(0, 1)] * 5\n",
    "\n",
    "# Variable assignments\n",
    "functions = [None, None, np.sin, lambda x: np.exp(x[:, 0]) + 2 * x[:, 1], lambda x: 2 * x]\n",
    "\n",
    "# All together\n",
    "anm = sempler.ANM(A, functions, noise_distributions)\n",
    "\n",
    "# Sampling from the observational setting\n",
    "samples1 = anm.sample(100)\n",
    "\n",
    "\n",
    "# Sampling under a noise intervention on variable 1\n",
    "samples2 = anm.sample(100, noise_interventions={1: noise.normal(0, 1)})\n",
    "\n",
    "# Sampling under a noise intervention on variable 0 and a do intervention on variable 2:\n",
    "\n",
    "samples3 = anm.sample(100,\n",
    "                     noise_interventions={0: noise.normal()},\n",
    "                     do_interventions={2: noise.uniform()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb653f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1414424  0.04006606 0.1214319  2.49015961 5.01002124]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(samples1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "999fea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.66304528e-03  2.86553921e+00  5.61652794e+00]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[0,1,0],\n",
    "             [0,0,1],\n",
    "             [0,0,0]])\n",
    "\n",
    "noise_distributions = [noise.normal(0, 1)] * 3\n",
    "functions = [\n",
    "    None,\n",
    "    lambda x: ( x + 1 ) * 3,\n",
    "    lambda x:  x * 2\n",
    "]\n",
    "anm = sempler.ANM(B, functions, noise_distributions)\n",
    "samples1 = anm.sample(100)\n",
    "print(np.mean(samples1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a63f413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.51285762, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 4.54277831, 0.        , 0.39388172],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 3.36973466, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sempler.generators import dag_avg_deg, intervention_targets\n",
    "\n",
    "dag_avg_deg(p=5, k=2, w_min=0.1, w_max=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e0976",
   "metadata": {},
   "source": [
    "Data Generation for av ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b86de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outer = 300\n",
    "inner = 300\n",
    "p = 6\n",
    "k = 2\n",
    "w_min=0.5\n",
    "w_max=5\n",
    "K = 5 # Number of interventions\n",
    "\n",
    "# Define means and variances for the noise distributions\n",
    "means = np.array([-2,-1,0,1,2,3])  # Means for the noise distributions\n",
    "variances = np.ones(p) \n",
    "\n",
    "for i in range(outer):\n",
    "    dag = dag_avg_deg(p=p, k=k, w_min=w_min, w_max=w_max, random_state=i)\n",
    "    \n",
    "    env = np.zeros(inner, dtype=int)  # Environment for observational data initialized to 0\n",
    "\n",
    "    dat = sempler.LGANM(dag, means = means, variances = variances).sample(inner)\n",
    "    dat = np.hstack([dat, env.reshape(-1,1)])  # Add environment column\n",
    "    \n",
    "    \n",
    "    int_target = np.array(intervention_targets(p-1, K, size = 1,replace=False, random_state=i)).flatten()\n",
    "    int_target = int_target + 1 # covariate 0 is not intervened on, so we shift the indices by 1\n",
    "    \n",
    "    for k in range(K):\n",
    "        \n",
    "        env = np.full(inner, int_target[k], dtype=int)  # Update environment column for each intervention\n",
    "        dat_tmp = sempler.LGANM(dag, means = means, variances = variances).sample(inner, shift_interventions={int_target[k]: (-10, 0)}) # shift intervention by mean = -10, variance = 0\n",
    "        dat_tmp = np.hstack([dat_tmp, env.reshape(-1,1),])  # Add environment column\n",
    "        dat = np.vstack([dat, dat_tmp])\n",
    "    \n",
    "    # Convert to DataFrame for easy saving\n",
    "    df = pd.DataFrame(dat)\n",
    "\n",
    "    # Save the data to a file\n",
    "    filename = f\"new_data_{i}.csv\"\n",
    "    dagname = f\"new_dag_{i}.txt\"\n",
    "    \n",
    "    # Save as CSV\n",
    "    df.to_csv(filename, index=False)\n",
    "    np.savetxt(dagname, dag, delimiter=',', fmt='%.6f')\n",
    "    \n",
    "      \n",
    "# print(dat[:5])  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29bd40",
   "metadata": {},
   "source": [
    "The next step is exporting the data to load in R\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
